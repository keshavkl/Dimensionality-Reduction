{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA is particularly useful for dimensionality reduction in supervised learning scenarios where the categories (labels) of the output variable are known.\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv')\n",
    "\n",
    "# Preview data\n",
    "print(data.head())\n",
    "\n",
    "# Handle missing values by creating a copy to avoid chained assignment\n",
    "data.loc[:, 'Age'] = data['Age'].fillna(data['Age'].median())\n",
    "data.loc[:, 'Embarked'] = data['Embarked'].fillna(data['Embarked'].mode()[0])\n",
    "\n",
    "# Drop columns that may not be useful for this analysis\n",
    "data = data.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "# Encoding categorical data\n",
    "encoder = OneHotEncoder()\n",
    "categorical_features = ['Pclass', 'Sex', 'Embarked']\n",
    "encoded_features = encoder.fit_transform(data[categorical_features]).toarray()\n",
    "encoded_feature_names = encoder.get_feature_names_out(categorical_features)\n",
    "\n",
    "# Create a DataFrame from encoded features and concatenate with the original dataset\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoded_feature_names)\n",
    "data_encoded = pd.concat([data.drop(categorical_features, axis=1), encoded_df], axis=1)\n",
    "\n",
    "# Scale data before applying PCA\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data_encoded.drop('Survived', axis=1))\n",
    "\n",
    "# Assuming data_scaled is the scaled data excluding 'Survived' and encoded features\n",
    "# 'Survived' is used as the target\n",
    "lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "lda_result = lda.fit_transform(data_scaled, data['Survived'])\n",
    "\n",
    "# Plot the result\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=lda_result[:, 0], y=[0]*len(lda_result), hue=data['Survived'], style=data['Survived'], palette='viridis')\n",
    "plt.title('LDA Result on Titanic Dataset')\n",
    "plt.xlabel('LD1')\n",
    "plt.yticks([])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Assuming data is preprocessed and ready for modeling\n",
    "X = data_scaled  # Features\n",
    "y = data['Survived']  # Target variable\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize LDA as classifier\n",
    "lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "X_train_lda = lda.fit_transform(X_train, y_train)\n",
    "X_test_lda = lda.transform(X_test)\n",
    "\n",
    "# Using LDA as classifier\n",
    "y_pred = lda.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Best Use Cases for LDA**\n",
    "\n",
    "**Binary or Multiclass Classification Problems:** LDA is inherently good for classification problems, especially when the classes are well-separated and the data distribution is approximately normal.\n",
    "\n",
    "**Dimensionality Reduction for Supervised Learning:** Unlike PCA, LDA takes class labels into account, making it more suitable when you need to preserve class discriminatory information.\n",
    "\n",
    "**Pattern Recognition and Feature Extraction:** In fields such as facial recognition, speech recognition, and biometrics, LDA helps in extracting features that convey the most class-discriminatory information.\n",
    "\n",
    "**Preprocessing for Other Machine Learning Models:** Reduced feature sets obtained via LDA can be used as inputs to other machine learning models, potentially increasing their effectiveness or reducing overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
